{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdRQLhpodeWE"
   },
   "source": [
    "# Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986,
     "status": "ok",
     "timestamp": 1702378020957,
     "user": {
      "displayName": "Marco Cascio",
      "userId": "02923373570292005281"
     },
     "user_tz": -60
    },
    "id": "SKxz_FqaJYbt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "\n",
    "# Imports PIL module\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1702378172132,
     "user": {
      "displayName": "Marco Cascio",
      "userId": "02923373570292005281"
     },
     "user_tz": -60
    },
    "id": "jZ4PI42TpULK"
   },
   "outputs": [],
   "source": [
    "# Configuration Settings\n",
    "n_packets = 100 # Number of packets within each packet group per ID, use even numbers. This defines the number of packet groups per ID (total_packets/n_packets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmIES6n8dmQ0"
   },
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IQR Amplitude values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file ID\n",
    "def extract_id_from_filename(filename):\n",
    "    \"\"\" Extract the ID from the filename, including the number and the trailing 'A' or 'B'. \"\"\"\n",
    "    match = re.search(r'(\\d+[mf][AB])\\.', filename) # e.g., 00001mA\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Load amplitudes from CSV files\n",
    "def load_amplitudes(directory):\n",
    "    # Initialize a dictionary to hold amplitudes\n",
    "    amplitudes = {}\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract ID from the file name\n",
    "            file_id = extract_id_from_filename(file_name)\n",
    "            if file_id:\n",
    "                # Collect amplitudes per ID[mf][AB] and store them in a dictionary\n",
    "                amplitudes[file_id] = df\n",
    "\n",
    "    return amplitudes\n",
    "\n",
    "# Folder to save the processed files\n",
    "output_folder = './output/'\n",
    "\n",
    "# Directory containing the CSV files to process\n",
    "input_directory = os.path.join(output_folder,'CSV','sanitized_amplitudes', 'IQR_amplitudes')\n",
    "\n",
    "# Process and save the files\n",
    "sanitized_amplitudes = load_amplitudes(input_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This dict will contain the packet groups for each ID\n",
    "split_sanitized_amplitudes = {}\n",
    "\n",
    "# Splitting the sanitized amplitudes into groups of 'n_packets' per ID\n",
    "for ID, amplitude_values in sanitized_amplitudes.items():\n",
    "    split_sanitized_amplitudes[ID] = []\n",
    "    # Calculate the number of full groups that can be made\n",
    "    num_full_groups = len(amplitude_values) // n_packets\n",
    "\n",
    "    for i in range(num_full_groups):\n",
    "        # Calculate the start index for each group\n",
    "        start_index = i * n_packets\n",
    "        # Calculate the end index for each group\n",
    "        end_index = start_index + n_packets\n",
    "        # Extract the group from amplitude_values\n",
    "        split_amplitude_group = amplitude_values[start_index:end_index]\n",
    "        # Append the group to the corresponding ID's list\n",
    "        split_sanitized_amplitudes[ID].append(split_amplitude_group)\n",
    "\n",
    "    # Handle any remaining elements that didn't form a full group\n",
    "    if len(amplitude_values) % n_packets != 0:\n",
    "        # Add the remaining elements as a separate group\n",
    "        split_sanitized_amplitudes[ID].append(amplitude_values[num_full_groups * n_packets:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kamHVCa7PEn"
   },
   "source": [
    "## Split data into Train, Validation, and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702378177048,
     "user": {
      "displayName": "Marco Cascio",
      "userId": "02923373570292005281"
     },
     "user_tz": -60
    },
    "id": "OBIyC_B82LJi"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to group keys in sanitized_amplitudes by their ID, e.g., ['00001': ['A': '00001mA', 'B': '00001mB']]\n",
    "groups = {}\n",
    "# Iterate over each key in the dictionary split_sanitized_amplitudes\n",
    "for key in split_sanitized_amplitudes.keys():\n",
    "    # Extract the ID part of the key\n",
    "    id = key[:-2]  # Assuming the last two characters are 'mA' or 'mB', 'fA' or 'fB'\n",
    "    # If this ID is not already in the groups dictionary, add it with subgroups 'A' and 'B'\n",
    "    if id not in groups:\n",
    "        groups[id] = {'A': [], 'B': []}\n",
    "    # Depending on whether the key ends with 'A' or 'B', add it to the respective subgroup\n",
    "    if key.endswith('A'):\n",
    "        groups[id]['A'].append(key)\n",
    "    elif key.endswith('B'):\n",
    "        groups[id]['B'].append(key)\n",
    "\n",
    "# Convert groups to a list and shuffle\n",
    "grouped_items = list(groups.values())\n",
    "\n",
    "# Extract all keys ending with 'A' from each group for the training set\n",
    "train_keys = [key for group in grouped_items for key in group['A']] # all IDs ending with 'A' are used for training\n",
    "# Extract all keys ending with 'B' from each group for validation and test sets\n",
    "val_and_test_keys = [key for group in grouped_items for key in group['B']] # all IDs ending with 'B' are used for validation and testing\n",
    "\n",
    "# Create the training set dictionary using the train keys\n",
    "train_set = {key: split_sanitized_amplitudes[key] for key in train_keys}\n",
    "# Create the validation and test set dictionary using the validation and test keys\n",
    "val_test_sets = {key: split_sanitized_amplitudes[key] for key in val_and_test_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YFUMlMO7e_m"
   },
   "source": [
    "## Generate Probes and Gallery for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702378270805,
     "user": {
      "displayName": "Marco Cascio",
      "userId": "02923373570292005281"
     },
     "user_tz": -60
    },
    "id": "fnSe5utx5git",
    "outputId": "71666e63-57e0-42c3-85fa-73acf06d4bf3"
   },
   "outputs": [],
   "source": [
    "# Function to create probe and gallery sets for the training data\n",
    "def create_train_probe_gallery(dataset):\n",
    "    probe = {}\n",
    "    gallery = {}\n",
    "    # Iterate through each ID in the dataset\n",
    "    for key in dataset.keys():\n",
    "        amplitudes = dataset[key]\n",
    "        # Split the amplitudes into two equal halves\n",
    "        half_length = len(amplitudes) // 2\n",
    "        probe_packets = amplitudes[:half_length]\n",
    "        gallery_packets = amplitudes[half_length:]\n",
    "        \n",
    "        # Assign the first half to the probe and the second half to the gallery\n",
    "        probe[key] = probe_packets\n",
    "        gallery[key] = gallery_packets\n",
    "\n",
    "    return probe, gallery\n",
    "\n",
    "# Function to create probe and gallery sets for validation and test data\n",
    "def create_valtest_probe_gallery(dataset, val_n_probe = 1, val_n_gallery = 1, test_n_probe = 1, test_n_gallery = 1):\n",
    "    val_probe = {}\n",
    "    val_gallery = {}\n",
    "\n",
    "    test_probe = {}\n",
    "    test_gallery = {}\n",
    "    \n",
    "    # Iterate through each ID in the dataset\n",
    "    for key in dataset.keys():\n",
    "        amplitudes = dataset[key]\n",
    "\n",
    "        # Divide the packet groups into specified numbers for validation and test sets\n",
    "        val_probe[key] = amplitudes[0:val_n_probe]\n",
    "        val_gallery[key] = amplitudes[val_n_probe:val_n_probe+val_n_gallery]\n",
    "\n",
    "        test_probe[key] = amplitudes[val_n_probe+val_n_gallery:(val_n_probe+val_n_gallery)+test_n_probe]\n",
    "        test_gallery[key] = amplitudes[(val_n_probe+val_n_gallery)+test_n_probe:((val_n_probe+val_n_gallery)+test_n_probe)+test_n_gallery]\n",
    "\n",
    "    return val_probe, val_gallery, test_probe, test_gallery\n",
    "\n",
    "# Create probe and gallery sets for train, validation, and test data\n",
    "train_probe, train_gallery = create_train_probe_gallery(train_set)\n",
    "val_probe, val_gallery, test_probe, test_gallery = create_valtest_probe_gallery(val_test_sets, val_n_probe = 2, val_n_gallery = 2, test_n_probe = 3, test_n_gallery = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBD2l9kI8ATS"
   },
   "source": [
    "## Generate Magnitude Heatmaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84902,
     "status": "ok",
     "timestamp": 1702378357449,
     "user": {
      "displayName": "Marco Cascio",
      "userId": "02923373570292005281"
     },
     "user_tz": -60
    },
    "id": "fHpQRWWRoeg6",
    "outputId": "6c15a4fd-08cb-4dec-ea13-38ce8ef24779"
   },
   "outputs": [],
   "source": [
    "def save_heatmap_image(data, output_path):\n",
    "  # Plotting the Magnitude of WiFi Signal without axes and colorbar\n",
    "  #plt.figure(figsize=(12, 6))\n",
    "  plt.figure()\n",
    "  plt.imshow(data, aspect='auto')\n",
    "  plt.axis('off')  # Disable the axis\n",
    "\n",
    "  # Saving the plot to a BytesIO object\n",
    "  buffer = BytesIO()\n",
    "  plt.savefig(buffer, format='png', bbox_inches='tight', pad_inches=0)\n",
    "  plt.close()\n",
    "  buffer.seek(0)  # Rewind the buffer to the beginning so you can read its content\n",
    "\n",
    "  # Open the image using PIL and convert to RGB (dropping alpha channel)\n",
    "  img = Image.open(buffer)\n",
    "  rgb_img = img.convert('RGB')\n",
    "\n",
    "  # Save the RGB image\n",
    "  rgb_img.save(output_path, format='PNG')\n",
    "\n",
    "  # Saving the plot to a BytesIO object to return the binary data\n",
    "  #buffer = BytesIO()\n",
    "  #plt.savefig(buffer, bbox_inches='tight', pad_inches=0, facecolor='white', edgecolor='white')\n",
    "  #plt.close()\n",
    "  #buffer.seek(0)  # Rewind the buffer to the beginning so you can read its content\n",
    "\n",
    "  # Write the buffer content to a file to save the image\n",
    "  #with open(output_path, \"wb\") as f:\n",
    "      #f.write(buffer.read())\n",
    "  return\n",
    "\n",
    "##################### TRAIN IMAGES ##########################\n",
    "\n",
    "# Generate and save image data for train probes\n",
    "if train_probe:\n",
    "  # Folder to save the train probes\n",
    "  output_path = os.path.join(output_folder,'ImageData','D1', 'Probe')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "  # Iterate over each ID in the train_probe dictionary\n",
    "    for ID, group_list in train_probe.items():\n",
    "        # Iterate over each packet group for the current ID\n",
    "        for group_idx, group_packets in enumerate(group_list):\n",
    "            # Convert the group packets to a numpy array and drop the timestamp column\n",
    "            group_values = group_packets.drop(columns='timestamp').to_numpy()\n",
    "            \n",
    "            # Define the filename using the probe ID and group index\n",
    "            filename = f\"{ID}_{group_idx}.png\"\n",
    "            \n",
    "            # Save the heatmap image for the current group\n",
    "            save_heatmap_image(group_values, os.path.join(output_path, filename))\n",
    "\n",
    "# Generate and save image data for train gallery\n",
    "if train_gallery:\n",
    "  # Folder to save the train gallery\n",
    "  output_path = os.path.join(output_folder,'ImageData','D1','Gallery')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "    # Iterate over each ID in the train_gallery dictionary\n",
    "    for ID, group_list in train_gallery.items():\n",
    "        # Iterate over each packet group for the current ID\n",
    "        for group_idx, group_packets in enumerate(group_list):\n",
    "            # Convert the group packets to a numpy array and drop the timestamp column\n",
    "            group_values = group_packets.drop(columns='timestamp').to_numpy()\n",
    "            \n",
    "            # Define the filename using the probe ID and group index\n",
    "            filename = f\"{ID}_{group_idx}.png\"\n",
    "            \n",
    "            # Save the heatmap image for the current group\n",
    "            save_heatmap_image(group_values, os.path.join(output_path, filename))\n",
    "\n",
    "##################### VAL IMAGES ############################\n",
    "\n",
    "# Generate and save image data for val probes\n",
    "if val_probe:\n",
    "  # Folder to save the val probes\n",
    "  output_path = os.path.join(output_folder,'ImageData','D2v','Probe')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "  # Iterate over each ID in the val_probe dictionary\n",
    "    for ID, group_list in val_probe.items():\n",
    "        # Iterate over each packet group for the current ID\n",
    "        for group_idx, group_packets in enumerate(group_list):\n",
    "            # Convert the group packets to a numpy array and drop the timestamp column\n",
    "            group_values = group_packets.drop(columns='timestamp').to_numpy()\n",
    "            \n",
    "            # Define the filename using the probe ID and group index\n",
    "            filename = f\"{ID}_{group_idx}.png\"\n",
    "            \n",
    "            # Save the heatmap image for the current group\n",
    "            save_heatmap_image(group_values, os.path.join(output_path, filename))\n",
    "\n",
    "# Generate and save image data for val gallery\n",
    "if val_gallery:\n",
    "  # Folder to save the val gallery\n",
    "  output_path = os.path.join(output_folder,'ImageData','D2v','Gallery')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "  # Iterate over each ID in the val_gallery dictionary\n",
    "    for ID, group_list in val_gallery.items():\n",
    "        # Iterate over each packet group for the current ID\n",
    "        for group_idx, group_packets in enumerate(group_list):\n",
    "            # Convert the group packets to a numpy array and drop the timestamp column\n",
    "            group_values = group_packets.drop(columns='timestamp').to_numpy()\n",
    "            \n",
    "            # Define the filename using the probe ID and group index\n",
    "            filename = f\"{ID}_{group_idx}.png\"\n",
    "            \n",
    "            # Save the heatmap image for the current group\n",
    "            save_heatmap_image(group_values, os.path.join(output_path, filename))\n",
    "\n",
    "##################### TEST IMAGES ##########################\n",
    "\n",
    "# Generate and save image data for test probes\n",
    "if test_probe:\n",
    "  # Folder to save the test probes\n",
    "  output_path = os.path.join(output_folder,'ImageData','D2t','Probe')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "  # Iterate over each ID in the test_probe dictionary\n",
    "    for ID, group_list in test_probe.items():\n",
    "        # Iterate over each packet group for the current ID\n",
    "        for group_idx, group_packets in enumerate(group_list):\n",
    "            # Convert the group packets to a numpy array and drop the timestamp column\n",
    "            group_values = group_packets.drop(columns='timestamp').to_numpy()\n",
    "            \n",
    "            # Define the filename using the probe ID and group index\n",
    "            filename = f\"{ID}_{group_idx}.png\"\n",
    "            \n",
    "            # Save the heatmap image for the current group\n",
    "            save_heatmap_image(group_values, os.path.join(output_path, filename))\n",
    "\n",
    "# Generate and save image data for test gallery\n",
    "if test_gallery:\n",
    "  # Folder to save the test gallery\n",
    "  output_path = os.path.join(output_folder,'ImageData','D2t','Gallery')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "  # Iterate over each ID in the test_gallery dictionary\n",
    "    for ID, group_list in test_gallery.items():\n",
    "        # Iterate over each packet group for the current ID\n",
    "        for group_idx, group_packets in enumerate(group_list):\n",
    "            # Convert the group packets to a numpy array and drop the timestamp column\n",
    "            group_values = group_packets.drop(columns='timestamp').to_numpy()\n",
    "            \n",
    "            # Define the filename using the probe ID and group index\n",
    "            filename = f\"{ID}_{group_idx}.png\"\n",
    "            \n",
    "            # Save the heatmap image for the current group\n",
    "            save_heatmap_image(group_values, os.path.join(output_path, filename))\n",
    "\n",
    "#!zip -r /content/CSV.zip /content/output/CSV\n",
    "#!zip -r /content/ImageData.zip /content/output/ImageData\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP7C1NKZZDP3AcNpD+R9ZIm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "WiPER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
